{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "646P-z5ldfph"
      },
      "source": [
        "### Only run to clear dataset from colab storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cKiE2btT3GJ"
      },
      "outputs": [],
      "source": [
        "!rm -rf dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPiLihE09-M2"
      },
      "source": [
        "## Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncrTy4HU-CBn",
        "outputId": "c0466dcb-264a-42ed-bd45-29af4d769a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchinfo, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF_D4iP6W8mr"
      },
      "source": [
        "# Variational Auto-Encoder\n",
        "Based on https://arxiv.org/pdf/2107.03298"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "daNslGHvTjD3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchaudio import datasets, transforms, save\n",
        "from torchinfo import summary\n",
        "import os\n",
        "import collections\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "import wave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR10WgVLkZGg"
      },
      "source": [
        "## Env Variables\n",
        "Used for variables that are consistent throughout the whole program for ease of testing and readability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OmpkgtNRkYw9"
      },
      "outputs": [],
      "source": [
        "nhead = 4\n",
        "dense_net = 1024\n",
        "epochs = 300\n",
        "batch_size = 32\n",
        "mel = transforms.MelSpectrogram(sample_rate=22050, n_fft=1024, win_length=512, hop_length=256, n_mels=80)\n",
        "inverseMel = transforms.InverseMelScale(sample_rate=22050, n_stft=(1024 // 2) + 1, n_mels=80)\n",
        "melToWav = transforms.GriffinLim(n_fft=1024, win_length=512, hop_length=256)\n",
        "loss_weight = [1, 1e-4, 1]\n",
        "validation = False\n",
        "retraining = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4WB_Q2Ajqog"
      },
      "source": [
        "## Drive Mounting\n",
        "\n",
        "Mounting the drive in order to save parameters in the case of a timeout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN4x8Ttrjq-2",
        "outputId": "4536f6ab-b13e-44a2-fd56-a63f16cc6b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxt9F1wFXZku"
      },
      "source": [
        "## Dataset Loading\n",
        "Using lj_speech dataset, a public domain speech and text dataset. This dataset will be saved to memory for each session in colab but will need to be redownloaded with each seperate session. If one wants to clear the preexisting dataset if this block times out, please use the utility at the top of this program. IMPORTANT NOTE: please wait for this block to finish running, if it is timed out only a subset of the data will be loaded into memory.\n",
        "\n",
        "Source: https://keithito.com/LJ-Speech-Dataset/lj_speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3-dT9LgX3_4",
        "outputId": "fb373511-b965-4dcb-d132-86f3b836e21f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.56G/2.56G [00:12<00:00, 221MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Data: (tensor([[-7.3242e-04, -7.6294e-04, -6.4087e-04,  ...,  7.3242e-04,\n",
            "          2.1362e-04,  6.1035e-05]]), 22050, 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition')\n",
            "Length of Dataset: 13100\n"
          ]
        }
      ],
      "source": [
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {dev}')\n",
        "path = os.path.join(os.getcwd(), 'dataset/')\n",
        "os.makedirs(path, exist_ok=True)\n",
        "rawData = datasets.LJSPEECH(path, download=True)\n",
        "print(f'Sample Data: {rawData[0]}')\n",
        "print(f'Length of Dataset: {len(rawData)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPjEgOhQn_Bf"
      },
      "source": [
        "## Text Tokenization\n",
        "Create a dictionary based on the training text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccyHHrI4aNTw",
        "outputId": "4dc261da-1ee4-477d-9699-e3d7667dbc05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lengh of vocab: 50\n",
            "[('p', 0), ('r', 1), ('i', 2), ('n', 3), ('t', 4), ('g', 5), (',', 6), (' ', 7), ('h', 8), ('e', 9), ('o', 10), ('l', 11), ('y', 12), ('s', 13), ('w', 14), ('c', 15), ('a', 16), ('d', 17), ('f', 18), ('m', 19), ('x', 20), ('b', 21), ('\\n', 22), ('v', 23), ('.', 24), ('u', 25), ('k', 26), ('j', 27), ('\"', 28), ('-', 29), (';', 30), ('(', 31), ('z', 32), (')', 33), (':', 34), (\"'\", 35), ('q', 36), ('!', 37), ('?', 38), ('â', 39), ('é', 40), ('à', 41), ('ê', 42), ('ü', 43), ('è', 44), ('“', 45), ('”', 46), ('’', 47), ('[', 48), (']', 49)]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Create a pair of dictionaries that map text to integers and vice versa.\n",
        "This is done to facilitate\n",
        "'''\n",
        "class Vocabulary():\n",
        "  def __init__(self):\n",
        "    self.vocab = []\n",
        "  '''\n",
        "  Create a dictionary of characters found in the text based, assign each\n",
        "  a unique numerical value.\n",
        "\n",
        "  Return two dictionaries of char->int, int->char\n",
        "  '''\n",
        "  def create_dictionary(self, freq):\n",
        "    self.vocab = list(freq.keys())\n",
        "    char_to_index = {word: index for index, word in enumerate(self.vocab)}\n",
        "    index_to_char = {index: word for word, index in char_to_index.items()}\n",
        "\n",
        "    return (char_to_index, index_to_char)\n",
        "\n",
        "f = open('dataset/LJSpeech-1.1/metadata.csv')\n",
        "count = collections.Counter()\n",
        "for line in f:\n",
        "  text = line.split('|')[2].lower()\n",
        "  count.update(list(text))\n",
        "\n",
        "vocab = Vocabulary()\n",
        "(char_to_index, index_to_char) = vocab.create_dictionary(count)\n",
        "print(f'Lengh of vocab: {len(char_to_index)}')\n",
        "print(list(char_to_index.items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXlmAljXziLC"
      },
      "source": [
        "## Dataset Loader + Collate Func\n",
        "Needed to pad sequences to the max length, otherwise cannot be used in a dataset loader and would cause batches not to work. This function will take in both the .wav and text, pad the wav before turning it into a spectrogram. It will then tokenize the text using the premade dictionary and then pad it to the max length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6S2AcMPztAa",
        "outputId": "c6df0909-19c3-4284-a54a-89a8a780991f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of Train: 4512\n",
            "Length of Test: 512\n"
          ]
        }
      ],
      "source": [
        "def paddingCollate(batch):\n",
        "  # ignore other form of text and ID for batching\n",
        "  waveform, _, text, _ = zip(*batch)\n",
        "  max_len = max(wave.shape[1] for wave in waveform)\n",
        "  padded_wave = [torch.nn.functional.pad(wave, (0, max_len - wave.shape[1])) for wave in waveform]\n",
        "  padded_wave = torch.stack(padded_wave, dim=0)\n",
        "  # transform to mel spectrogram for ease of use\n",
        "  spec = [mel(wave).permute(0, 2, 1) for wave in padded_wave]\n",
        "  padded_spec = torch.nn.utils.rnn.pad_sequence(spec, batch_first=True).squeeze(1)\n",
        "\n",
        "  tokenized_text = [[char_to_index.get(index, char_to_index[' ']) for index in list(sentence.lower())] for sentence in text]\n",
        "  tokenized_text = [torch.tensor(sent, dtype=torch.long) for sent in tokenized_text]\n",
        "  padded_text = torch.nn.utils.rnn.pad_sequence(tokenized_text, batch_first=True)\n",
        "\n",
        "  return padded_text, padded_spec\n",
        "\n",
        "# reduce dataset size to 5000\n",
        "reducedDataSize = list(range(0, 5000))\n",
        "reducedRawData = torch.utils.data.Subset(rawData, reducedDataSize)\n",
        "\n",
        "# define train and test split\n",
        "trainSize = int(0.9 * len(reducedDataSize))\n",
        "testSize = len(reducedDataSize) - trainSize\n",
        "train, test = torch.utils.data.random_split(reducedRawData, [trainSize, testSize])\n",
        "\n",
        "trainDatasetLoader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=paddingCollate)\n",
        "testDatasetLoader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True, collate_fn=paddingCollate)\n",
        "print(f'Length of Train: {len(trainDatasetLoader) * batch_size}')\n",
        "print(f'Length of Test: {len(testDatasetLoader) * batch_size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQdj8QTTXWw_"
      },
      "source": [
        "## Text Encoder\n",
        "Convolution layers with dropout, batch normalization and ReLU activation. Follow this with positional encoding, and then self attention blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AvnUdWqwZYHs"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Sinosoidal Positional Encoding\n",
        "Input: batch x seq len x embed len\n",
        "Output: batch x seq len x embed len\n",
        "\n",
        "Applies the sinosoidal positional encoding to the input's embedding. Should be\n",
        "functional accross all batches.\n",
        "'''\n",
        "def sinosoidal_position_encoding(token_size, embedding_dim, batch_size):\n",
        "  pos = torch.arange(0, token_size, device=dev).unsqueeze(1)\n",
        "  emb = torch.zeros(token_size, batch_size, embedding_dim, device=dev)\n",
        "\n",
        "  dividing_term = torch.pow(10000, 2*torch.arange(0, embedding_dim //2, device=dev)/embedding_dim)\n",
        "\n",
        "  # based on definition in Attention is All You Need\n",
        "  emb[:, 0, 0::2] = torch.sin(pos/dividing_term)\n",
        "  emb[:, 0, 1::2] = torch.cos(pos/dividing_term)\n",
        "\n",
        "  emb = emb.permute(1, 2, 0)\n",
        "\n",
        "  return emb\n",
        "\n",
        "'''\n",
        "Convolutional Layer Stack for Text Encoder\n",
        "Input: batch x seq len x embed len\n",
        "Output: batch x seq len x embed len\n",
        "Convolute each 1D sequence, batch norm, ReLU, and dropout.\n",
        "'''\n",
        "class ConvStack(torch.nn.Module):\n",
        "  def __init__(self, D, K):\n",
        "    super(ConvStack, self).__init__()\n",
        "    self.conv = torch.nn.Conv1d(D, D, K, bias=False)\n",
        "    self.norm = torch.nn.BatchNorm1d(D)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.dropout = torch.nn.Dropout1d()\n",
        "  def forward(self, X):\n",
        "    convolution = self.conv(X)\n",
        "    normalization = self.norm(convolution)\n",
        "    relu = self.relu(normalization)\n",
        "    output = self.dropout(relu)\n",
        "    return output\n",
        "\n",
        "'''\n",
        "Self Attention Layer\n",
        "Input: batch x seq len x embed len\n",
        "Output: batch x seq len x embed len\n",
        "Can take in either the direct query value or create the values on the fly.\n",
        "'''\n",
        "class SelfAttentionLayer(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(SelfAttentionLayer, self).__init__()\n",
        "    self.query = nn.Linear(data_dim, data_dim)\n",
        "    self.value = nn.Linear(data_dim, data_dim)\n",
        "    self.key = nn.Linear(data_dim, data_dim)\n",
        "\n",
        "  def forward(self, X):\n",
        "    Q = self.query(X)\n",
        "    V = self.value(X)\n",
        "    K = self.key(X)\n",
        "    attn = nn.functional.scaled_dot_product_attention(Q, V, K)\n",
        "    return attn\n",
        "\n",
        "\n",
        "'''\n",
        "Text Encoder Block\n",
        "Input: batch x seq len x em\n",
        "Output: batch x seq len x embed len\n",
        "\n",
        "Needs to utilize multiple permutations in order to work within Pytorch's built in encoder,\n",
        "sinusoidal positional encoding, and self attention.\n",
        "'''\n",
        "class TextEncoder(torch.nn.Module):\n",
        "  def __init__(self, embedding_size, conv_size, K):\n",
        "    super(TextEncoder, self).__init__()\n",
        "    self.embedding = torch.nn.Embedding(embedding_size, conv_size)\n",
        "    self.stack1 = ConvStack(conv_size, K)\n",
        "    self.stack2 = ConvStack(conv_size, K)\n",
        "    self.stack3 = ConvStack(conv_size, K)\n",
        "    self.stack4 = ConvStack(conv_size, K)\n",
        "    self.stack5 = ConvStack(conv_size, K)\n",
        "    self.attention1 = SelfAttentionLayer(conv_size)\n",
        "    self.attention2 = SelfAttentionLayer(conv_size)\n",
        "    self.attention3 = SelfAttentionLayer(conv_size)\n",
        "    self.attention4 = SelfAttentionLayer(conv_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    embed = self.embedding(X)\n",
        "    # permutate to shift order from [batch, seq len, embed len] to [batch, embed len, seq len]\n",
        "    embed = embed.permute(0, 2, 1)\n",
        "    conv1 = self.stack1(embed)\n",
        "    conv2 = self.stack2(conv1)\n",
        "    conv3 = self.stack3(conv2)\n",
        "    conv4 = self.stack4(conv3)\n",
        "    conv5 = self.stack5(conv4)\n",
        "\n",
        "    # add positional encoding to embedding, no grad\n",
        "    with torch.no_grad():\n",
        "      pos = sinosoidal_position_encoding(conv5.size(2), conv5.size(1), conv5.size(0))\n",
        "    conv_pos = conv5 + pos\n",
        "    conv_pos = conv_pos.permute(0, 2, 1)\n",
        "    attn1 = self.attention1(conv_pos)\n",
        "    attn2 = self.attention2(attn1)\n",
        "    attn3 = self.attention3(attn2)\n",
        "    attn4 = self.attention4(attn3)\n",
        "\n",
        "    return attn4\n",
        "\n",
        "if validation:\n",
        "  model = TextEncoder(2000, 256, 5).to(dev)\n",
        "  input_text = rawData[0][3].lower()\n",
        "  input_tensor = torch.tensor([char_to_index[item] for item in list(input_text)], device=dev).unsqueeze(0)\n",
        "  print(summary(model, input_data=input_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWJhL86Ucr2c"
      },
      "source": [
        "## Posterior Encoder\n",
        "Fully connected layers w/ dropout and ReLU activation followed by sinusoidal positional encoding.\n",
        "\n",
        "Attention layers are then stacked upon one another with Q = encoded spectrogram, K, V = encoded text. This should take the form of a self attention layer, a cross-attention layer, and a feed-forward NN with a hidden layer of 1024 and output size of 256.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aCxRlvBGhOmq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Self Attention Layer for Posterior Encoder\n",
        "Input: batch x seq len x embed len\n",
        "Output: batch x seq len x embed len\n",
        "Designed to work with self attention between\n",
        "'''\n",
        "class PosteriorSelfAttentionLayer(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(PosteriorSelfAttentionLayer, self).__init__()\n",
        "    self.query = nn.Linear(data_dim, data_dim)\n",
        "    self.value = nn.Linear(data_dim, data_dim)\n",
        "    self.key = nn.Linear(data_dim, data_dim)\n",
        "    self.d = data_dim\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, Q, V, K):\n",
        "    # based on definition in Attention is All You Need\n",
        "    QK = Q @ K\n",
        "    Y = self.softmax(QK).div(self.d ** 0.5)\n",
        "    output = (Y @ V.mT)\n",
        "    return output # permutate to return a form that can be added\n",
        "\n",
        "'''\n",
        "Attention Block for Posterior Encoder\n",
        "Input: batch x seq len x embed len\n",
        "Output: batch x seq len x embed len\n",
        "Utilizes a self attention layer, and a cross attention layer with a feed-forward NN.\n",
        "'''\n",
        "class AttentionBlock(torch.nn.Module):\n",
        "  def __init__(self, data_dim, head_num, hidden_dim):\n",
        "    super(AttentionBlock, self).__init__()\n",
        "    self.d = data_dim\n",
        "    self.attn_self = PosteriorSelfAttentionLayer(data_dim)\n",
        "    self.Q = nn.Linear(data_dim, data_dim)\n",
        "    self.V = nn.Linear(data_dim, data_dim)\n",
        "    self.K = nn.Linear(data_dim, data_dim)\n",
        "    self.attn_cross = nn.MultiheadAttention(data_dim, head_num, batch_first=True)\n",
        "    self.linear1 = nn.Linear(data_dim, hidden_dim)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_dim, 128)\n",
        "\n",
        "  def forward(self, Q, V, K):\n",
        "    attn_s = self.attn_self(Q, V, K)\n",
        "    #attn_c = self.attn_cross(attn_s, V.permute(0, 2, 1), K.permute(0, 2, 1))\n",
        "    lin1 = self.linear1(attn_s)\n",
        "    relu = self.relu1(lin1)\n",
        "    return self.linear2(relu)\n",
        "\n",
        "\n",
        "'''\n",
        "Posterior Encoder\n",
        "Input: batch x seq len x embed len, Spectrogram Y\n",
        "Output: batch x posterior probability\n",
        "\n",
        "Returns the posterior probability of the spectrogram given the encoded and transformed text.\n",
        "'''\n",
        "class PosteriorEncoder(torch.nn.Module):\n",
        "  def __init__(self, wav_dim, emb_dim):\n",
        "    super(PosteriorEncoder, self).__init__()\n",
        "    self.linear1 = nn.Linear(wav_dim, 256)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    self.dropout1 = torch.nn.Dropout()\n",
        "    self.linear2 = nn.Linear(256, emb_dim)\n",
        "    self.relu2 = torch.nn.ReLU()\n",
        "    self.dropout2 = torch.nn.Dropout()\n",
        "    # in this case, Q is transformed waveform (tgt) and V, K are the encoded text (memory)\n",
        "    self.attn1 = nn.TransformerDecoderLayer(emb_dim, nhead, dense_net, batch_first=True)\n",
        "    self.attn2 = nn.TransformerDecoderLayer(emb_dim, nhead, dense_net, batch_first=True)\n",
        "\n",
        "\n",
        "  def forward(self, spectrogram, text):\n",
        "    # prenet for spectrogram\n",
        "    lin1 = self.linear1(spectrogram)\n",
        "    relu1 = self.relu1(lin1)\n",
        "    drop1 = self.dropout1(relu1)\n",
        "    lin2 = self.linear2(drop1)\n",
        "    relu2 = self.relu2(lin2)\n",
        "    transformed_spec = self.dropout2(relu2)\n",
        "    # add sinusoidal positional encoding\n",
        "    with torch.no_grad():\n",
        "      pos = sinosoidal_position_encoding(transformed_spec.size(1), transformed_spec.size(2), transformed_spec.size(0)).permute(0, 2, 1)\n",
        "    pos_spec = transformed_spec + pos\n",
        "    attn_1 = self.attn1(pos_spec, text)\n",
        "    attn = self.attn2(attn_1, text)\n",
        "    return attn\n",
        "\n",
        "if validation:\n",
        "  sampleSpec = rawData[0][0]\n",
        "  model = PosteriorEncoder(80, 256).to(dev)\n",
        "  input_waveform_tensor = mel(sampleSpec).permute(0, 2, 1).to(dev)\n",
        "  input_tensor = torch.randint(0, 2000, (1, 131, 256), dtype=torch.float, device=dev)\n",
        "  print(summary(model, input_data=[input_waveform_tensor, input_tensor]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-utJEapD5pOv"
      },
      "source": [
        "## Prior Encoder\n",
        "Utilizes Glow Blocks, which contain an actnorm layer, an invertible 1x1 convolution layer, and an affine-coupling layer. This implementation is based off of this explanation: https://ameroyer.github.io/reading-notes/generative%20models/2019/05/07/glow_generative_flow_with_invertible_1x1_convolution.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gUUtONO5AIXe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "ActNorm Layer\n",
        "Similar to batch norm, but parameters aren't determined for each batch but rather\n",
        " a set bias and log standard deviation is initalized and trained.\n",
        "'''\n",
        "class ActNormLayer(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(ActNormLayer, self).__init__()\n",
        "    self.initalized = False\n",
        "    self.log_weight = nn.Parameter(torch.ones(1, 1, data_dim, device=dev))\n",
        "    self.bias = nn.Parameter(torch.zeros(1, 1, data_dim, device=dev))\n",
        "\n",
        "  def forward(self, X):\n",
        "    if not self.initalized:\n",
        "      with torch.no_grad(): # don't want to calculate each time and propogated, want mean and std to be set once\n",
        "        mean = X.mean(dim=(0, 1), keepdim=True)\n",
        "        std = X.std(dim=(0, 1), keepdim=True)\n",
        "        #print('in initialization')\n",
        "        self.mean = mean.to(dev)\n",
        "        self.log_std = torch.log(std + 0.000001).to(dev)\n",
        "        #self.bias.copy_(1 / (std + 0.000001)) # find mean and variance along sequence length and batch size\n",
        "        #self.log_weight.data.copy_(-1 * mean / (std + 0.000001))\n",
        "        self.initalized = True\n",
        "    #print('in forward')\n",
        "    # expand to fill batch size\n",
        "    log_weight = self.log_weight.expand(X.shape[0], -1, -1)\n",
        "    bias = self.bias.expand(X.shape[0], -1, -1)\n",
        "    mean = self.mean.expand(X.shape[0], -1, -1)\n",
        "    log_std = self.log_std.expand(X.shape[0], -1, -1)\n",
        "\n",
        "    #torch.nn.utils.clip_grad_norm_(self.parameters(), 1.0) # clip gradients in order to prevent exploding gradients in actnorm\n",
        "    return (X - mean) * torch.exp(log_weight) * torch.exp(-1 * log_std) + bias\n",
        "\n",
        "'''\n",
        "Invertible 1x1 convolution.\n",
        "'''\n",
        "class Conv1x1(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(Conv1x1, self).__init__()\n",
        "    W = torch.randn(data_dim, data_dim)\n",
        "    P, L, U = torch.linalg.lu(W) # LU decomp as mentioned in paper, enforce invertibility\n",
        "    self.W = torch.unsqueeze(P @ L @ U, 2).to(dev) # unsqueeze 2nd dim to add a third dim\n",
        "\n",
        "  def forward(self, X):\n",
        "    return nn.functional.conv1d(X, self.W, bias=None).permute(0, 2, 1)\n",
        "\n",
        "class AffineCouplingLayer(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(AffineCouplingLayer, self).__init__()\n",
        "    self.split_id = data_dim // 2\n",
        "    self.text_reduce = nn.Linear(data_dim, data_dim//2)\n",
        "    self.decoder = nn.TransformerDecoderLayer(data_dim//2, nhead, dense_net, batch_first=True)\n",
        "    self.s_transform = nn.Linear(data_dim // 2, data_dim // 2)\n",
        "    self.t_transform = nn.Linear(data_dim // 2, data_dim // 2)\n",
        "\n",
        "  def forward(self, Z_i, X):\n",
        "    z_1, z_2 = torch.split(Z_i, self.split_id, dim=2)\n",
        "    X_reduced = self.text_reduce(X)\n",
        "    decoded = self.decoder(z_1, X_reduced)\n",
        "    s = self.s_transform(decoded)\n",
        "    t = self.t_transform(decoded)\n",
        "    y_1 = z_1\n",
        "    y_2 = z_2 * torch.exp(s) + t\n",
        "    return torch.cat((y_1, y_2), dim=2)\n",
        "\n",
        "class glowBlock(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(glowBlock, self).__init__()\n",
        "    self.act_norm = ActNormLayer(data_dim)\n",
        "    self.norm = nn.LayerNorm(data_dim)\n",
        "    self.conv = Conv1x1(data_dim)\n",
        "    self.coupling = AffineCouplingLayer(data_dim)\n",
        "\n",
        "  def forward(self, X, Z_i):\n",
        "    norm = self.act_norm(Z_i)\n",
        "    #norm = self.norm(Z_i)\n",
        "    norm = norm.permute(0, 2, 1)\n",
        "    convoluted = self.conv(norm)\n",
        "    coupled = self.coupling(convoluted, X)\n",
        "    return coupled\n",
        "\n",
        "class PriorEncoder(torch.nn.Module):\n",
        "  def __init__(self, data_dim):\n",
        "    super(PriorEncoder, self).__init__()\n",
        "    self.glow1 = glowBlock(data_dim)\n",
        "    self.glow2 = glowBlock(data_dim)\n",
        "    self.glow3 = glowBlock(data_dim)\n",
        "    self.glow4 = glowBlock(data_dim)\n",
        "    self.glow5 = glowBlock(data_dim)\n",
        "    self.glow6 = glowBlock(data_dim)\n",
        "\n",
        "  def forward(self, X, Z_i):\n",
        "    g1 = self.glow1(X, Z_i)\n",
        "    g2 = self.glow2(X, g1)\n",
        "    g3 = self.glow3(X, g2)\n",
        "    g4 = self.glow4(X, g3)\n",
        "    g5 = self.glow5(X, g4)\n",
        "    g6 = self.glow6(X, g5)\n",
        "    return g6\n",
        "\n",
        "if validation:\n",
        "  Z_i = torch.randn(1, 127, 256).to(dev)\n",
        "  X = torch.randint(0, 50, (1, 131, 256), dtype=torch.float).to(dev)\n",
        "  model = PriorEncoder(256).to(dev)\n",
        "  print(summary(model, input_data=[X, Z_i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYDsD7wcAI7-"
      },
      "source": [
        "## Length Predictor\n",
        "From the encoded text representation, the predicted length of the Mel Spectrogram will be predicted. The loss for this specific module will not be passed back to the text encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Re7dlB5ZDK1w"
      },
      "outputs": [],
      "source": [
        "class LengthPredictor(torch.nn.Module):\n",
        "  def __init__(self, text_dim):\n",
        "    super(LengthPredictor, self).__init__()\n",
        "    self.linear1 = nn.Linear(text_dim, 256)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(256, 1)\n",
        "    self.softplus = nn.Softplus() # enforce an always positive value for character-utterance length\n",
        "\n",
        "  def forward(self, X):\n",
        "    lin1 = self.linear1(X)\n",
        "    relu = self.relu(lin1)\n",
        "    lin2 = self.linear2(relu)\n",
        "    output = self.softplus(lin2)\n",
        "    sum = torch.sum(output, dim=1)\n",
        "    return sum\n",
        "\n",
        "if validation:\n",
        "  model = LengthPredictor(512)\n",
        "  input_tensor = torch.zeros([1, 128, 512])\n",
        "  print(summary(model, input_data=input_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h6k8lyBDLgh"
      },
      "source": [
        "## Decoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m2ZMj1ULDOGe"
      },
      "outputs": [],
      "source": [
        "class PostNetBlock(torch.nn.Module):\n",
        "  def __init__(self, D, K, last_layer=False):\n",
        "    super(PostNetBlock, self).__init__()\n",
        "    self.conv = nn.Conv1d(D, D, K, bias=False, padding = (K - 1) // 2)\n",
        "    self.bn = nn.BatchNorm1d(D)\n",
        "    self.act = nn.Tanh()\n",
        "    self.ll = last_layer\n",
        "\n",
        "  def forward(self, pred_spec):\n",
        "    c = self.conv(pred_spec)\n",
        "    batch_norm = self.bn(c)\n",
        "    activation = self.act(batch_norm)\n",
        "    if self.ll:\n",
        "      return batch_norm\n",
        "    else:\n",
        "      return activation\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "  def __init__(self, emb_dim, K):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.deco1 = nn.TransformerDecoderLayer(emb_dim, nhead, dense_net, batch_first=True)\n",
        "    self.deco2 = nn.TransformerDecoderLayer(emb_dim, nhead, dense_net, batch_first=True)\n",
        "    self.conv1 = PostNetBlock(emb_dim, K)\n",
        "    self.conv2 = PostNetBlock(emb_dim, K)\n",
        "    self.conv3 = PostNetBlock(emb_dim, K)\n",
        "    self.conv4 = PostNetBlock(emb_dim, K)\n",
        "    self.conv5 = PostNetBlock(emb_dim, K, last_layer=True)\n",
        "    self.dim_red = nn.Linear(emb_dim, 80)\n",
        "\n",
        "  def forward(self, X, Z):\n",
        "    # in this case, Q is transformed waveform (tgt) and V, K are the encoded text (memory)\n",
        "    decoder1 = self.deco1(Z, X)\n",
        "    Y_initial = self.deco2(decoder1, X)\n",
        "    Y_initial = Y_initial.permute(0, 2, 1)\n",
        "    c1 = self.conv1(Y_initial)\n",
        "    c2 = self.conv2(c1)\n",
        "    c3 = self.conv3(c2)\n",
        "    c4 = self.conv4(c3)\n",
        "    c5 = self.conv5(c4)\n",
        "    complement = torch.add(Y_initial, c5)\n",
        "    complement = complement.permute(0, 2, 1)\n",
        "    Y_hat = self.dim_red(complement)\n",
        "    return Y_hat\n",
        "\n",
        "if validation:\n",
        "  Z_i = torch.randn(1, 127, 256)\n",
        "  X = torch.randint(0, 2000, (1, 131, 256), dtype=torch.float)\n",
        "  model = Decoder(256, 5)\n",
        "  print(summary(model, input_data=[X, Z_i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28lUsL60fYT"
      },
      "source": [
        "## VAENAR Training Model\n",
        "Construct the training model as defined in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M5UgBhZ-0jy1"
      },
      "outputs": [],
      "source": [
        "class VARNAR_train(torch.nn.Module):\n",
        "  def __init__(self, dict_size, data_dim, wave_dim, K):\n",
        "    super(VARNAR_train, self).__init__()\n",
        "    self.textEnc = TextEncoder(dict_size, data_dim, K)\n",
        "    self.posteriorEnc = PosteriorEncoder(wave_dim, data_dim)\n",
        "    self.lenPred = LengthPredictor(data_dim)\n",
        "    self.priorEnc = PriorEncoder(data_dim)\n",
        "    self.decoder = Decoder(data_dim, K)\n",
        "    self.data_dim = data_dim\n",
        "\n",
        "  def forward(self, X, Y, length):\n",
        "    encodedText = self.textEnc(X)\n",
        "    detachedEncodedText = encodedText.detach()\n",
        "    pred_length = self.lenPred(detachedEncodedText)\n",
        "    predictedGaussian = torch.randn(X.shape[0], length, self.data_dim).to(dev)\n",
        "    posteriorDist = self.posteriorEnc(Y, encodedText)\n",
        "    priorDist = self.priorEnc(encodedText, predictedGaussian)\n",
        "    decoded_val = self.decoder(encodedText, posteriorDist)\n",
        "\n",
        "    return decoded_val, priorDist, posteriorDist, pred_length\n",
        "\n",
        "if validation:\n",
        "  model = VARNAR_train(50, 256, 80, 5).to(dev)\n",
        "  input_text = rawData[0][2].lower()\n",
        "  sample_X = torch.tensor([char_to_index[item] for item in list(input_text)]).unsqueeze(0).to(dev)\n",
        "  sample_Y = mel(sampleSpec).permute(0, 2, 1).to(dev)\n",
        "  print(summary(model, input_data=[sample_X, sample_Y, torch.tensor(sample_Y.size(1)).to(dev)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UurjcVFWDO7s"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVi1ByNyDTJC",
        "outputId": "0435f18b-89ea-4f41-d97d-298f19016fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 1 | len loss: 3.204684019088745 | Z loss: 89047.515625 | Y loss: 1408.248046875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 2 | len loss: 0.7950267195701599 | Z loss: 51475.75390625 | Y loss: 1332.198486328125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 3 | len loss: 0.14021655917167664 | Z loss: 38403.953125 | Y loss: 1276.15087890625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 4 | len loss: 0.043970610946416855 | Z loss: 30126.427734375 | Y loss: 1227.4072265625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 5 | len loss: 0.025022249668836594 | Z loss: 21078.6953125 | Y loss: 1185.4874267578125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 6 | len loss: 0.025027254596352577 | Z loss: 7093.0 | Y loss: 1142.99755859375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 7 | len loss: 0.02961771748960018 | Z loss: 2938.192138671875 | Y loss: 1104.245361328125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 8 | len loss: 0.04104795306921005 | Z loss: 2209.349365234375 | Y loss: 1069.6773681640625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 9 | len loss: 0.026785578578710556 | Z loss: 1817.433349609375 | Y loss: 1030.7845458984375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 10 | len loss: 0.031582579016685486 | Z loss: 1630.890380859375 | Y loss: 1000.98291015625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 11 | len loss: 0.030833814293146133 | Z loss: 1486.661865234375 | Y loss: 970.38427734375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 12 | len loss: 0.022876007482409477 | Z loss: 1366.3006591796875 | Y loss: 935.4742431640625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 13 | len loss: 0.042366065084934235 | Z loss: 1517.7039794921875 | Y loss: 916.67431640625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 14 | len loss: 0.017507970333099365 | Z loss: 1234.57470703125 | Y loss: 870.7532348632812\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 15 | len loss: 0.01137303002178669 | Z loss: 1073.5328369140625 | Y loss: 843.0882568359375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 16 | len loss: 0.009611012414097786 | Z loss: 974.944091796875 | Y loss: 818.0592041015625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 17 | len loss: 0.013108283281326294 | Z loss: 985.284423828125 | Y loss: 797.83203125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 18 | len loss: 0.01638817973434925 | Z loss: 1025.0108642578125 | Y loss: 774.4724731445312\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 19 | len loss: 0.00807897187769413 | Z loss: 929.4881591796875 | Y loss: 739.4884643554688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 20 | len loss: 0.007819756865501404 | Z loss: 916.3545532226562 | Y loss: 715.9969482421875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 21 | len loss: 0.008841016329824924 | Z loss: 882.7666625976562 | Y loss: 698.2123413085938\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 22 | len loss: 0.010846953839063644 | Z loss: 853.441650390625 | Y loss: 669.6203002929688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 23 | len loss: 0.007261023391038179 | Z loss: 815.3921508789062 | Y loss: 652.1842651367188\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 24 | len loss: 0.005477570928633213 | Z loss: 788.0598754882812 | Y loss: 626.7501831054688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 25 | len loss: 0.004801308736205101 | Z loss: 764.3263549804688 | Y loss: 601.4880981445312\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 26 | len loss: 0.005183802451938391 | Z loss: 764.073486328125 | Y loss: 592.5426635742188\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 27 | len loss: 0.009637271985411644 | Z loss: 719.4578857421875 | Y loss: 573.9910888671875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 28 | len loss: 0.004922680556774139 | Z loss: 704.7006225585938 | Y loss: 556.2833862304688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 29 | len loss: 0.007763839326798916 | Z loss: 695.605712890625 | Y loss: 547.4788208007812\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 30 | len loss: 0.006483033299446106 | Z loss: 656.2230224609375 | Y loss: 523.0839233398438\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 31 | len loss: 0.006243839394301176 | Z loss: 658.9922485351562 | Y loss: 518.3931884765625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 32 | len loss: 0.0067056892439723015 | Z loss: 638.4204711914062 | Y loss: 506.2249450683594\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 33 | len loss: 0.006950207520276308 | Z loss: 606.8294067382812 | Y loss: 484.36090087890625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 34 | len loss: 0.007827370427548885 | Z loss: 608.677978515625 | Y loss: 475.8597412109375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 35 | len loss: 0.006224676035344601 | Z loss: 593.990966796875 | Y loss: 470.4759521484375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 36 | len loss: 0.007272667717188597 | Z loss: 572.3718872070312 | Y loss: 451.1557312011719\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 37 | len loss: 0.007429019547998905 | Z loss: 559.6509399414062 | Y loss: 434.9185485839844\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 38 | len loss: 0.006694665178656578 | Z loss: 564.64794921875 | Y loss: 455.9435119628906\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 39 | len loss: 0.015539209358394146 | Z loss: 617.2896118164062 | Y loss: 441.17816162109375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 40 | len loss: 0.006332799326628447 | Z loss: 542.767822265625 | Y loss: 419.0346984863281\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 41 | len loss: 0.006108549423515797 | Z loss: 516.6194458007812 | Y loss: 409.2532043457031\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 42 | len loss: 0.005961671471595764 | Z loss: 496.28753662109375 | Y loss: 406.44683837890625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 43 | len loss: 0.0059537203051149845 | Z loss: 484.0895690917969 | Y loss: 404.74212646484375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 44 | len loss: 0.006530319806188345 | Z loss: 474.447998046875 | Y loss: 400.0750427246094\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 45 | len loss: 0.007704135961830616 | Z loss: 444.051513671875 | Y loss: 383.5283508300781\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 46 | len loss: 0.006043114699423313 | Z loss: 420.0606994628906 | Y loss: 381.6783142089844\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 47 | len loss: 0.005177181679755449 | Z loss: 379.18011474609375 | Y loss: 374.9621276855469\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 48 | len loss: 0.00925780925899744 | Z loss: 414.6307373046875 | Y loss: 406.8786926269531\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 49 | len loss: 0.007616673596203327 | Z loss: 387.1135559082031 | Y loss: 388.1243896484375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 50 | len loss: 0.006082157604396343 | Z loss: 385.2967529296875 | Y loss: 379.80999755859375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 51 | len loss: 0.005274204537272453 | Z loss: 366.0474853515625 | Y loss: 357.53057861328125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 52 | len loss: 0.006437129806727171 | Z loss: 347.6404724121094 | Y loss: 352.81341552734375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 53 | len loss: 0.00665299640968442 | Z loss: 345.0227355957031 | Y loss: 364.4647521972656\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 54 | len loss: 0.005187960807234049 | Z loss: 312.32000732421875 | Y loss: 354.76385498046875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 55 | len loss: 0.007134856656193733 | Z loss: 294.1977233886719 | Y loss: 346.3232421875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 56 | len loss: 0.005393476691097021 | Z loss: 277.816650390625 | Y loss: 338.4901123046875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 57 | len loss: 0.0049000089056789875 | Z loss: 271.9971008300781 | Y loss: 347.48614501953125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 58 | len loss: 0.006149250082671642 | Z loss: 254.55819702148438 | Y loss: 332.17095947265625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 59 | len loss: 0.00439641484990716 | Z loss: 253.3765106201172 | Y loss: 344.5668029785156\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 60 | len loss: 0.005030804313719273 | Z loss: 245.72467041015625 | Y loss: 323.5164489746094\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 61 | len loss: 0.004868194926530123 | Z loss: 247.8495635986328 | Y loss: 323.7843933105469\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 62 | len loss: 0.004135848022997379 | Z loss: 219.58612060546875 | Y loss: 325.2237243652344\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 63 | len loss: 0.005878239870071411 | Z loss: 223.40565490722656 | Y loss: 314.8068542480469\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 64 | len loss: 0.005237042438238859 | Z loss: 214.34613037109375 | Y loss: 316.61700439453125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 65 | len loss: 0.005426583345979452 | Z loss: 210.0235137939453 | Y loss: 316.4680480957031\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 66 | len loss: 0.004952716641128063 | Z loss: 203.80438232421875 | Y loss: 310.4970703125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 67 | len loss: 0.008827399462461472 | Z loss: 202.93699645996094 | Y loss: 308.6453857421875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 68 | len loss: 0.008898040279746056 | Z loss: 197.93606567382812 | Y loss: 315.576171875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 69 | len loss: 0.004400117788463831 | Z loss: 187.19996643066406 | Y loss: 306.4888916015625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 70 | len loss: 0.004600869491696358 | Z loss: 188.63735961914062 | Y loss: 298.48077392578125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 71 | len loss: 0.004739091731607914 | Z loss: 189.42807006835938 | Y loss: 316.38079833984375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 72 | len loss: 0.005886608734726906 | Z loss: 185.15313720703125 | Y loss: 302.3834533691406\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 73 | len loss: 0.004401677288115025 | Z loss: 183.49192810058594 | Y loss: 294.5731201171875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 74 | len loss: 0.00508823711425066 | Z loss: 193.79383850097656 | Y loss: 309.4381103515625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 75 | len loss: 0.005162214860320091 | Z loss: 181.56097412109375 | Y loss: 289.4374084472656\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 76 | len loss: 0.005071697756648064 | Z loss: 176.71400451660156 | Y loss: 289.5425109863281\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 77 | len loss: 0.0042372108437120914 | Z loss: 178.7838134765625 | Y loss: 297.8282165527344\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 78 | len loss: 0.0041367001831531525 | Z loss: 170.0866241455078 | Y loss: 285.5965576171875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 79 | len loss: 0.0038268286734819412 | Z loss: 169.897216796875 | Y loss: 282.5992736816406\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 80 | len loss: 0.004785978700965643 | Z loss: 161.7093505859375 | Y loss: 279.54547119140625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 81 | len loss: 0.0042828284204006195 | Z loss: 171.3062744140625 | Y loss: 285.536376953125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 82 | len loss: 0.005009437445551157 | Z loss: 167.5347900390625 | Y loss: 276.9210205078125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 83 | len loss: 0.006037482991814613 | Z loss: 167.98605346679688 | Y loss: 286.7182922363281\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 84 | len loss: 0.005394225008785725 | Z loss: 176.35311889648438 | Y loss: 290.1917419433594\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 85 | len loss: 0.004811041057109833 | Z loss: 158.58685302734375 | Y loss: 274.4384460449219\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 86 | len loss: 0.004316292237490416 | Z loss: 164.60276794433594 | Y loss: 273.3264465332031\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 87 | len loss: 0.004302261862903833 | Z loss: 170.98779296875 | Y loss: 275.1155090332031\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 88 | len loss: 0.004676192067563534 | Z loss: 158.7166290283203 | Y loss: 278.22686767578125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 89 | len loss: 0.004944965709000826 | Z loss: 166.44651794433594 | Y loss: 282.7421875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 90 | len loss: 0.0041891480796039104 | Z loss: 166.0596923828125 | Y loss: 274.30291748046875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 91 | len loss: 0.0047620139084756374 | Z loss: 159.3569793701172 | Y loss: 263.9148864746094\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 92 | len loss: 0.0076464274898171425 | Z loss: 160.73367309570312 | Y loss: 263.265869140625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 93 | len loss: 0.005203442182391882 | Z loss: 161.43887329101562 | Y loss: 258.3924560546875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 94 | len loss: 0.004669890273362398 | Z loss: 165.0597686767578 | Y loss: 262.8489685058594\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 95 | len loss: 0.003652897197753191 | Z loss: 149.7391357421875 | Y loss: 261.8065490722656\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 96 | len loss: 0.0033050982747226954 | Z loss: 151.97962951660156 | Y loss: 255.37327575683594\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 97 | len loss: 0.003960707690566778 | Z loss: 162.01051330566406 | Y loss: 273.1036071777344\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 98 | len loss: 0.004289544653147459 | Z loss: 157.6024932861328 | Y loss: 260.3425598144531\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 99 | len loss: 0.003429848700761795 | Z loss: 155.5984344482422 | Y loss: 248.5054473876953\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 100 | len loss: 0.003334334585815668 | Z loss: 155.54676818847656 | Y loss: 248.1951904296875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 101 | len loss: 0.0038673023227602243 | Z loss: 158.3885955810547 | Y loss: 244.43397521972656\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 102 | len loss: 0.0038736946880817413 | Z loss: 157.38760375976562 | Y loss: 241.72157287597656\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 103 | len loss: 0.005346910562366247 | Z loss: 158.780517578125 | Y loss: 248.55210876464844\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 104 | len loss: 0.0042937081307172775 | Z loss: 161.77703857421875 | Y loss: 244.82484436035156\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 105 | len loss: 0.005649316590279341 | Z loss: 155.26048278808594 | Y loss: 239.10809326171875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 106 | len loss: 0.004029128234833479 | Z loss: 152.17669677734375 | Y loss: 246.974609375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 107 | len loss: 0.004363903775811195 | Z loss: 152.82505798339844 | Y loss: 232.9408721923828\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 108 | len loss: 0.003435119753703475 | Z loss: 155.19407653808594 | Y loss: 230.91441345214844\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 109 | len loss: 0.0035121049731969833 | Z loss: 151.9385528564453 | Y loss: 232.6483154296875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 110 | len loss: 0.0037456429563462734 | Z loss: 152.8111114501953 | Y loss: 234.2714385986328\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 111 | len loss: 0.002935980446636677 | Z loss: 151.94488525390625 | Y loss: 227.27874755859375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 112 | len loss: 0.003111467929556966 | Z loss: 151.65292358398438 | Y loss: 230.46446228027344\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 113 | len loss: 0.004020403604954481 | Z loss: 157.49026489257812 | Y loss: 229.02139282226562\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 114 | len loss: 0.003710452001541853 | Z loss: 159.5248260498047 | Y loss: 234.2899932861328\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 115 | len loss: 0.005233030766248703 | Z loss: 167.09954833984375 | Y loss: 252.3059844970703\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 116 | len loss: 0.00409654900431633 | Z loss: 162.23123168945312 | Y loss: 235.81980895996094\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 117 | len loss: 0.0037480418104678392 | Z loss: 156.3508758544922 | Y loss: 219.2610321044922\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 118 | len loss: 0.0035156256053596735 | Z loss: 154.92813110351562 | Y loss: 224.50070190429688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 119 | len loss: 0.0043572913855314255 | Z loss: 157.57029724121094 | Y loss: 244.0590362548828\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 120 | len loss: 0.003584848018363118 | Z loss: 157.75994873046875 | Y loss: 219.76199340820312\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 121 | len loss: 0.003319804323837161 | Z loss: 157.93992614746094 | Y loss: 220.9949493408203\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 122 | len loss: 0.003190005663782358 | Z loss: 158.14794921875 | Y loss: 221.14306640625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 123 | len loss: 0.004649743903428316 | Z loss: 169.54867553710938 | Y loss: 231.01095581054688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 124 | len loss: 0.0038756730500608683 | Z loss: 168.90757751464844 | Y loss: 218.2870330810547\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 125 | len loss: 0.0032031650189310312 | Z loss: 164.91189575195312 | Y loss: 224.08218383789062\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 126 | len loss: 0.004178354050964117 | Z loss: 162.25875854492188 | Y loss: 217.44110107421875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 127 | len loss: 0.003054027445614338 | Z loss: 162.3141326904297 | Y loss: 211.71714782714844\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 128 | len loss: 0.00321160233579576 | Z loss: 164.2513427734375 | Y loss: 210.67413330078125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 129 | len loss: 0.0032573086209595203 | Z loss: 161.1751251220703 | Y loss: 212.31494140625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 130 | len loss: 0.0031113778240978718 | Z loss: 160.31141662597656 | Y loss: 207.6923828125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 131 | len loss: 0.0026738846208900213 | Z loss: 163.34201049804688 | Y loss: 208.09320068359375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 132 | len loss: 0.003285710234194994 | Z loss: 162.5777587890625 | Y loss: 210.03744506835938\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 133 | len loss: 0.0030298838391900063 | Z loss: 163.9689178466797 | Y loss: 217.9776153564453\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 134 | len loss: 0.002707434818148613 | Z loss: 156.86236572265625 | Y loss: 205.7779541015625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 135 | len loss: 0.0032961489632725716 | Z loss: 165.99203491210938 | Y loss: 214.84561157226562\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 136 | len loss: 0.0032026953995227814 | Z loss: 158.1079864501953 | Y loss: 208.78463745117188\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 137 | len loss: 0.0026388007681816816 | Z loss: 163.40963745117188 | Y loss: 214.4718475341797\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 138 | len loss: 0.0032864806707948446 | Z loss: 160.71005249023438 | Y loss: 205.49754333496094\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 139 | len loss: 0.003045994322746992 | Z loss: 163.11676025390625 | Y loss: 229.83560180664062\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 140 | len loss: 0.0037848656065762043 | Z loss: 162.39100646972656 | Y loss: 208.27581787109375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 141 | len loss: 0.0028605100233107805 | Z loss: 165.09124755859375 | Y loss: 201.0155029296875\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 142 | len loss: 0.003331315703690052 | Z loss: 159.69129943847656 | Y loss: 195.8094940185547\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 143 | len loss: 0.003144156886264682 | Z loss: 158.09095764160156 | Y loss: 197.55413818359375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 144 | len loss: 0.003699328750371933 | Z loss: 161.41314697265625 | Y loss: 196.666015625\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 145 | len loss: 0.0030822299886494875 | Z loss: 154.44674682617188 | Y loss: 197.13763427734375\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 146 | len loss: 0.002982771024107933 | Z loss: 157.9087371826172 | Y loss: 197.1249542236328\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 147 | len loss: 0.0033729516435414553 | Z loss: 154.99607849121094 | Y loss: 199.26034545898438\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 148 | len loss: 0.002670865971595049 | Z loss: 158.276611328125 | Y loss: 192.66390991210938\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 149 | len loss: 0.003203975036740303 | Z loss: 156.3828887939453 | Y loss: 190.79031372070312\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 150 | len loss: 0.0030133400578051805 | Z loss: 161.1915740966797 | Y loss: 192.3265838623047\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 151 | len loss: 0.0027823159471154213 | Z loss: 159.20901489257812 | Y loss: 189.36715698242188\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 152 | len loss: 0.003021102398633957 | Z loss: 163.54896545410156 | Y loss: 207.2394256591797\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 153 | len loss: 0.0033759325742721558 | Z loss: 165.16647338867188 | Y loss: 197.22433471679688\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 154 | len loss: 0.003324329387396574 | Z loss: 163.72540283203125 | Y loss: 184.1739501953125\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 155 | len loss: 0.0030754697509109974 | Z loss: 163.98175048828125 | Y loss: 184.60923767089844\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 156 | len loss: 0.002842547371983528 | Z loss: 162.86936950683594 | Y loss: 184.79786682128906\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 157 | len loss: 0.0030201300978660583 | Z loss: 166.27981567382812 | Y loss: 190.32888793945312\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 158 | len loss: 0.004418039228767157 | Z loss: 171.16159057617188 | Y loss: 188.84170532226562\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 159 | len loss: 0.0032265568152070045 | Z loss: 160.8501739501953 | Y loss: 183.4547882080078\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n",
            "Epoch 160 | len loss: 0.003165151458233595 | Z loss: 160.3733673095703 | Y loss: 183.76712036132812\n",
            "1/4 done\n",
            "1/2 done\n",
            "3/4 done\n"
          ]
        }
      ],
      "source": [
        "train_model = VARNAR_train(50, 256, 80, 5)\n",
        "train_model.to(dev)\n",
        "\n",
        "if retraining:\n",
        "  para_pth = '/content/drive/MyDrive/TTS_Parameters/Attempt 2/05-12 22:31.pth'\n",
        "  params = torch.load(para_pth, weights_only=True)\n",
        "  train_model.load_state_dict(params)\n",
        "  kl_weight = 0.1 * ((len(trainDatasetLoader) // batch_size) * 0.001 * epochs)\n",
        "else:\n",
        "  kl_weight = 0.1\n",
        "\n",
        "train_model.train()\n",
        "\n",
        "optimizer = torch.optim.Adam(train_model.parameters(), lr=1e-4)\n",
        "\n",
        "len_loss_tracker = []\n",
        "Z_loss_tracker = []\n",
        "Y_loss_tracker = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  batch_num = 1\n",
        "  lenLossTotal = 0\n",
        "  zLossTotal = 0\n",
        "  yLossTotal = 0\n",
        "  for x_batch, y_batch in trainDatasetLoader:\n",
        "    if batch_num == len(trainDatasetLoader) // 4:\n",
        "      print('1/4 done')\n",
        "    elif batch_num == len(trainDatasetLoader) // 2:\n",
        "      print('1/2 done')\n",
        "    elif batch_num == (len(trainDatasetLoader) // 4) * 3:\n",
        "      print('3/4 done')\n",
        "    x_batch = x_batch.to(dev)\n",
        "    y_batch = y_batch.to(dev)\n",
        "    length = torch.tensor(y_batch.shape[1], device=dev)\n",
        "    #print(f'Length shape: {length.shape}')\n",
        "    y_hat, Z_hat, Z, len_hat = train_model(x_batch, y_batch, length)\n",
        "    #print(f'y_hat shape: {y_hat.shape}')\n",
        "    #print(f'Z shape: {Z.shape}')\n",
        "    #print(f'Z_hat shape: {Z_hat.shape}')\n",
        "    #print(f'Len_hat shape: {len_hat.shape}')\n",
        "\n",
        "    lenLossTotal += (len_loss := torch.nn.functional.mse_loss(torch.log(len_hat.squeeze(1)), torch.log(length.repeat(len_hat.shape[0]))))\n",
        "    zLossTotal += (latent_loss := torch.nn.functional.kl_div(torch.log_softmax(Z_hat + 1e-7, dim=-1), torch.softmax(Z + 1e-7, dim=-1), reduction='batchmean', log_target=False))\n",
        "    yLossTotal += (spec_loss := torch.nn.functional.mse_loss(y_hat, y_batch))\n",
        "    total_loss = sum([len_loss * loss_weight[0], latent_loss * loss_weight[1] * kl_weight, spec_loss * loss_weight[2]])\n",
        "\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    '''\n",
        "    len_loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    otherLoss = sum([latent_loss, spec_loss])\n",
        "    otherLoss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    '''\n",
        "    kl_weight = min(1.0, kl_weight + 0.001)\n",
        "    batch_num += 1\n",
        "\n",
        "  if i % 3 == 0 and i != 0:\n",
        "    now = datetime.datetime.now()\n",
        "    torch.save(train_model.state_dict(), f'/content/drive/MyDrive/TTS_Parameters/{now.strftime(\"%m-%d %H:%M\")}.pth')\n",
        "  len_loss_tracker.append(lenLossTotal)\n",
        "  Z_loss_tracker.append(zLossTotal)\n",
        "  Y_loss_tracker.append(yLossTotal)\n",
        "\n",
        "\n",
        "  print(f'Epoch {i+1} | len loss: {lenLossTotal / len(trainDatasetLoader)} | Z loss: {zLossTotal / len(trainDatasetLoader)} | Y loss: {yLossTotal / len(trainDatasetLoader)}')\n",
        "  with open('/content/drive/MyDrive/TTS_Parameters/loss_vals.txt', 'a') as f:\n",
        "    f.write(f'Epoch {i+1}\\n')\n",
        "    f.write(f'len loss: {lenLossTotal / len(trainDatasetLoader)}\\n')\n",
        "    f.write(f'Z loss: {zLossTotal / len(trainDatasetLoader)}\\n')\n",
        "    f.write(f'Y loss: {yLossTotal / len(trainDatasetLoader)}\\n\\n')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "WevoRPPIjzFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model.eval()\n",
        "\n",
        "len_loss_tracker = []\n",
        "Z_loss_tracker = []\n",
        "Y_loss_tracker = []\n",
        "\n",
        "len_accuracy = 0\n",
        "z_accuracy = 0\n",
        "y_accuracy = 0\n",
        "for x_batch, y_batch in testDatasetLoader:\n",
        "  if batch_num == len(testDatasetLoader) // 4:\n",
        "    print('1/4 done')\n",
        "  elif batch_num == len(testDatasetLoader) // 2:\n",
        "    print('1/2 done')\n",
        "  elif batch_num == (len(testDatasetLoader) // 4) * 3:\n",
        "    print('3/4 done')\n",
        "  x_batch = x_batch.to(dev)\n",
        "  y_batch = y_batch.to(dev)\n",
        "  length = torch.tensor(y_batch.shape[1], device=dev)\n",
        "  #print(f'Length shape: {length.shape}')\n",
        "  y_hat, Z_hat, Z, len_hat = train_model(x_batch, y_batch, length)\n",
        "  #print(f'y_hat shape: {y_hat.shape}')\n",
        "  #print(f'Z shape: {Z.shape}')\n",
        "  #print(f'Z_hat shape: {Z_hat.shape}')\n",
        "  #print(f'Len_hat shape: {len_hat.shape}')\n",
        "\n",
        "  len_accuracy += (len_loss := torch.nn.functional.mse_loss(torch.log(len_hat.squeeze(1)), torch.log(length.repeat(len_hat.shape[0]))))\n",
        "  z_accuracy += (latent_loss := torch.nn.functional.kl_div(torch.log_softmax(Z_hat + 1e-7, dim=-1), torch.softmax(Z + 1e-7, dim=-1), reduction='batchmean', log_target=False))\n",
        "  yLossTotal += (spec_loss := torch.nn.functional.mse_loss(y_hat, y_batch))\n",
        "  y_accuracy = sum([len_loss * loss_weight[0], latent_loss * loss_weight[1] * kl_weight, spec_loss * loss_weight[2]])\n",
        "\n",
        "len_accuracy /= len(testDatasetLoader)\n",
        "z_accuracy /= len(testDatasetLoader)\n",
        "y_accuracy /= len(testDatasetLoader)\n"
      ],
      "metadata": {
        "id": "lXGlCrSAj0uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM5rAag4vApO"
      },
      "source": [
        "## VAENAR Inference Model\n",
        "Same structure as the other model but different flow of data (using inferenced Z rather than the ground truth one)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sZ1v7ZkmvJQD"
      },
      "outputs": [],
      "source": [
        "class VAENAR_test(torch.nn.Module):\n",
        "  def __init__(self, dict_size, data_dim, wave_dim, K):\n",
        "    super(VAENAR_test, self).__init__()\n",
        "    self.textEnc = TextEncoder(dict_size, data_dim, K)\n",
        "    self.posteriorEnc = PosteriorEncoder(wave_dim, data_dim)\n",
        "    self.lenPred = LengthPredictor(data_dim)\n",
        "    self.priorEnc = PriorEncoder(data_dim)\n",
        "    self.decoder = Decoder(data_dim, K)\n",
        "    self.data_dim = data_dim\n",
        "\n",
        "  def forward(self, X):\n",
        "    encodedText = self.textEnc(X)\n",
        "    detachedEncodedText = encodedText.detach()\n",
        "    pred_length = self.lenPred(detachedEncodedText)\n",
        "    pred_length = int(pred_length.item())\n",
        "    predictedGaussian = torch.randn(X.shape[0], pred_length, self.data_dim).to(dev)\n",
        "    #posteriorDist = self.posteriorEnc(Y, encodedText)\n",
        "    priorDist = self.priorEnc(encodedText, predictedGaussian)\n",
        "    decoded_val = self.decoder(encodedText, priorDist)\n",
        "\n",
        "    return decoded_val\n",
        "\n",
        "if validation:\n",
        "  model = VAENAR_test(50, 256, 80, 5).to(dev)\n",
        "  input_text = rawData[0][2].lower()\n",
        "  sample_X = torch.tensor([char_to_index[item] for item in list(input_text)]).unsqueeze(0).to(dev)\n",
        "  sample_Y = mel(sampleSpec).permute(0, 2, 1).to(dev)\n",
        "  print(summary(model, input_data=[sample_X, sample_Y]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1eCAj_U24sf"
      },
      "source": [
        "## Inference\n",
        "Run if this folder isn't created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "72dSQ79W5H9W"
      },
      "outputs": [],
      "source": [
        "!mkdir ModelOutputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQqsQySJ26AA",
        "outputId": "cb8c2f1d-c120-48cd-9f9f-d34e334aee78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give an input for the model: Printing, in the only sense with which we are at present concerned\n",
            "Model has outputted\n"
          ]
        }
      ],
      "source": [
        "test_model = VAENAR_test(50, 512, 80, 5)\n",
        "test_model.to(dev)\n",
        "\n",
        "para_pth = '/content/drive/MyDrive/TTS_Parameters/Attempt 2/05-12 22:22.pth'\n",
        "testParams = torch.load(para_pth, weights_only=True, map_location=torch.device('cpu'))\n",
        "test_model.load_state_dict(testParams, strict=False)\n",
        "\n",
        "test_model.eval()\n",
        "\n",
        "X = input('Give an input for the model: ')\n",
        "X_tensor = torch.tensor([char_to_index[item] for item in list(X.lower())]).unsqueeze(0).to(dev)\n",
        "y_hat = test_model(X_tensor)\n",
        "invertedSpec = inverseMel(y_hat.permute(0, 2, 1).cpu())\n",
        "wavFile = melToWav(invertedSpec)\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "save(f'/content/ModelOutputs/{now.strftime(\"%m-%d %H:%M\")}.wav', wavFile, 22050)\n",
        "print('Model has outputted')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}